{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2cad482",
      "metadata": {},
      "source": [
        "# Livrable final du projet - Projet Green Graph\n",
        "*Equipe CesiCDP - Chef de projet : Leila | Opérateurs : Tom, Edwin*</br>\n",
        "## Sommaire :\n",
        "    1. Introduction\n",
        "\n",
        "    PARTIE 1 : Modélisation\n",
        "    2. Rappel de la modélisation formelle\n",
        "        2.1. Résumé des hypothèses et représentations\n",
        "        2.2. Justification du maintien de la modélisation\n",
        "    3. Méthodes de résolution\n",
        "        3.1. Choix des algorithmes\n",
        "        3.2. Description des algorithmes \n",
        "        3.3. Complexité des algorithmes \n",
        "\n",
        "    PARTIE 2 : Implémentation et exploitation\n",
        "    4. Implémentation\n",
        "        4.1. Détails de l’implémentation des algorithmes\n",
        "        4.2. Cas de test représentatifs\n",
        "        4.3. Résultats observés sur les tests\n",
        "    5. Étude expérimentale\n",
        "        5.1. Méthodologie du plan d’expérience\n",
        "        5.2. Analyse des performances \n",
        "        5.3. Limites observées\n",
        "        5.4. Perspectives d’amélioration\n",
        "\n",
        "    6. Plan de Travail et Organisation du Projet\n",
        "        6.1. Étapes prévues \n",
        "\n",
        "    7. Conclusion\n",
        "\n",
        "    8. Annexes\n",
        "        8.1. Glossaire\n",
        "        8.2. Références bibliographiques\n",
        "        8.3. Annexes techniques "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb7b178",
      "metadata": {},
      "source": [
        "### 1. Introduction\n",
        "Dans la continuité de notre premier livrable, ce document final a pour objectif de présenter l'ensemble de la démarche menée autour du projet Green Graph, de la modélisation initiale à l'évaluation expérimentale des solutions implémentées.\n",
        "\n",
        "Pour rappel, on se questionnait sur comment réduire l’impact environnemental des tournées de livraison tout en optimisant les coûts opérationnels.<br>\n",
        "En modélisant ce problème à partir du **Problème du Voyageur de Commerce (PVC)** complété avec des contraintes réalistes :\n",
        "* **Coût ou restriction de passage sur certaines arêtes :** Certaines routes peuvent être plus coûteuses ou interdites,\n",
        "* **Dépendances entre visites :** Une ville ne peut être visitée qu'après en avoir visité une autre,\n",
        "\n",
        "nous avons pu définir une approche formelle qui répond aux besoins de planification d'un trajet routier réel.\n",
        "\n",
        "La première partie du projet consiste à modéliser mathématiquement le problème, nous y détaillons également les méthodes de résolution sélectionnées, en mettant en lumière les raisons de nos choix algorithmiques, ainsi que la complexité associée.\n",
        "\n",
        "La seconde partie est dédiée à la mise en œuvre : l’implémentation des algorithmes, les cas de test choisis, et l’analyse des résultats obtenus. Cette étude expérimentale permet d'évaluer la performance des solutions proposées, leurs limitations, et d’ouvrir la voie à de nouvelles perspectives d’amélioration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce3cfde",
      "metadata": {},
      "source": [
        "## Partie 1\n",
        "### 2. Rappel de la modélisation formelle\n",
        "##### 2.1. Résumé des hypothèses et représentations\n",
        "Pour rappel, notre réseau routié est représenté sous la forme d'un graphe  non orienté $G = (V, E)$, où :\n",
        "* $V = {v_0, v_1, ..., v_n}$ représente les sommets (le dépôt $v_0$ et les points de livraison),\n",
        "* $E$ l’ensemble des arêtes, représentant les routes entre les sommets,\n",
        "* $E_{interdit}$ l'ensemble des routes inaccessible,\n",
        "* $D$ l'ensemble des dépendances entre les villes.\n",
        "\n",
        "Chaque arête $(u, v) \\in E$ est associée à un coût $c_{uv}$ (distance), une variable binaire $x_{uv} \\in \\{0, 1\\}$ indique si l’arête $(u, v)$ est utilisée dans la tournée. Si l'arête $x_{uv} \\in E_{interdit}$, alors $x_{uv}=0$.\n",
        "\n",
        "Chaque élément $d \\in D$ est une paire ordonnée $(v_i, v_j)$ signifiant le sommet $v_i$ doit être visité avant le sommet $v_j$.<br>\n",
        "On note $t_i \\in \\mathbb{N}$, une variable qui représente l’ordre de visite du sommet $v_i$ dans la tournée, pour chaque dépendance $(v_i, v_j) \\in D$ : $t_i<t_j$.\n",
        "\n",
        "On souligne qu'on ne visite chaque sommet $V$ de $G$ exactement une fois et on retourne au point de départ $v_0$, l'objectif est de miniser le coûts total de la tournée en respectant les contraintes soit $\\min \\sum_{(u,v) \\in E} c_{uv} \\cdot x_{uv}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7465143",
      "metadata": {},
      "outputs": [],
      "source": [
        "def geocode_city(city_name):\n",
        "    from geopy.geocoders import Nominatim\n",
        "    \"\"\"Converts a city name to coordinates (latitude, longitude)\"\"\"\n",
        "    geolocator = Nominatim(user_agent=\"routing_app\", timeout=10)\n",
        "    location = geolocator.geocode(city_name,country_codes=\"FR\")\n",
        "    \n",
        "    if location:\n",
        "        return (location.latitude, location.longitude)\n",
        "    else:\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e44ab5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def GenerateCityMapFromCSV(size):\n",
        "    \"\"\"Generates a list of cities from a CSV file\"\"\"\n",
        "    import pandas as pd\n",
        "    import random\n",
        "    from tqdm import tqdm\n",
        "    \n",
        "    city_map = {} \n",
        "    df = pd.read_csv(\"CityName.csv\", on_bad_lines='skip')\n",
        "    city_list = df['City'].dropna().tolist()\n",
        "    city_list = random.sample(city_list, size)\n",
        "    for city in tqdm(city_list):\n",
        "        lat, lon = geocode_city(city) \n",
        "        if  (lat or lon) is not None:\n",
        "            city_map[city] = (lat,lon)\n",
        "    return city_map\n",
        "\n",
        "Cities = GenerateCityMapFromCSV(5)\n",
        "print(Cities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640481cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def calculate_travel_time(departure_city, arrival_city, city_map, mode, osrm_link, params):\n",
        "    \"\"\"\n",
        "    Calculates travel time between two cities using the OSRM API.\n",
        "\n",
        "    Args:\n",
        "        departure_city (str): Name of the departure city.\n",
        "        arrival_city (str): Name of the arrival city.\n",
        "        city_map (dict): Mapping of city names to coordinates (latitude, longitude).\n",
        "        mode (str): Transportation mode (driving, cycling, walking).\n",
        "        osrm_link (str): Base URL of the OSRM server.\n",
        "        params (dict): Additional parameters for the OSRM API.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (time in seconds, distance in meters, formatted time)\n",
        "    \"\"\"\n",
        "    # Get city coordinates\n",
        "    try:\n",
        "        lat1, lon1 = city_map[departure_city]\n",
        "        lat2, lon2 = city_map[arrival_city]\n",
        "    except ValueError as e:\n",
        "        return None, None, str(e)\n",
        "\n",
        "    # Build the URL for the OSRM API\n",
        "    url = f\"{osrm_link}/{mode}/{lon1},{lat1};{lon2},{lat2}\"\n",
        "\n",
        "    # Call the OSRM API\n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=50)\n",
        "        response.raise_for_status()\n",
        "    except requests.RequestException as e:\n",
        "        return None, None, f\"API request error: {e}\"\n",
        "\n",
        "    data = response.json()\n",
        "\n",
        "    if data.get(\"code\") != \"Ok\":\n",
        "        return None, None, f\"OSRM API error: {data.get('code')}\"\n",
        "\n",
        "    # Extract time and distance\n",
        "    route = data[\"routes\"][0]\n",
        "    duration_seconds = route[\"duration\"]\n",
        "    distance_meters = route[\"distance\"]\n",
        "\n",
        "    # Format time\n",
        "    hours, remainder = divmod(duration_seconds, 3600)\n",
        "    minutes, _ = divmod(remainder, 60)\n",
        "\n",
        "    formatted_time = \"\"\n",
        "    if hours:\n",
        "        formatted_time += f\"{int(hours)} hour{'s' if hours > 1 else ''} \"\n",
        "    if minutes:\n",
        "        formatted_time += f\"{int(minutes)} minute{'s' if minutes > 1 else ''}\"\n",
        "\n",
        "    return duration_seconds, distance_meters, formatted_time.strip()\n",
        "\n",
        "def display_route(departure_city, arrival_city, city_map, mode, osrm_link, params):\n",
        "    \"\"\"\n",
        "    Displays route information between two cities.\n",
        "    \"\"\"\n",
        "    modes = {\n",
        "        \"driving\": \"by car\",\n",
        "        \"cycling\": \"by bicycle\",\n",
        "        \"walking\": \"on foot\"\n",
        "    }\n",
        "\n",
        "    duration, distance, message = calculate_travel_time(\n",
        "        departure_city, arrival_city, city_map, mode, osrm_link, params\n",
        "    )\n",
        "\n",
        "    if duration is None:\n",
        "        print(message)\n",
        "        return\n",
        "\n",
        "    print(f\"Route from {departure_city} to {arrival_city} {modes.get(mode, '')}:\")\n",
        "    print(f\"Travel time: {message}\")\n",
        "    print(f\"Distance: {distance / 1000:.1f} km\")\n",
        "\n",
        "\n",
        "def matrix_generation(cities_dict, mode, link, params, toPrint=False):\n",
        "    import pytz\n",
        "    from datetime import datetime\n",
        "    from tqdm import tqdm\n",
        "    \n",
        "    # Extract city names from the dictionary\n",
        "    city_names = list(cities_dict.keys())\n",
        "    \n",
        "    # Initialiser la matrice avec des zéros\n",
        "    n = len(city_names)\n",
        "    matrix = [[None for _ in range(n)] for _ in range(n)]\n",
        "    \n",
        "    # Remplir la diagonale avec [0, 0]\n",
        "    for i in range(n):\n",
        "        if toPrint:\n",
        "            matrix[i][i] = [\"00:00:00\", 0]\n",
        "        else:\n",
        "            matrix[i][i] = [0, 0]\n",
        "    \n",
        "    # Calculer uniquement la moitié supérieure de la matrice\n",
        "    for i in tqdm(range(n)):\n",
        "        for j in range(i+1, n):  # Commence à i+1 pour éviter la diagonale et les doublons\n",
        "            sourceCity = city_names[i]\n",
        "            destinationCity = city_names[j]\n",
        "            \n",
        "            duration, distance, _ = calculate_travel_time(sourceCity, destinationCity, cities_dict, mode, link, params)\n",
        "            \n",
        "            if toPrint:\n",
        "                result = [datetime.fromtimestamp(duration, tz=pytz.utc).strftime('%H:%M:%S'), int(distance / 1000)]\n",
        "            else:\n",
        "                result = [duration, int(distance / 1000)]\n",
        "            \n",
        "            # Stocker le résultat à la fois dans la partie supérieure et inférieure\n",
        "            matrix[i][j] = result\n",
        "            matrix[j][i] = result  # Exploiter la symétrie\n",
        "    \n",
        "    return matrix, city_names\n",
        "\n",
        "# Utilisation avec votre dictionnaire de villes\n",
        "# Supposons que Cities est votre dictionnaire comme montré dans votre document\n",
        "\n",
        "link = \"http://router.project-osrm.org/route/v1/\"\n",
        "params = {\n",
        "    \"overview\": \"false\",\n",
        "    \"alternatives\": \"false\",\n",
        "}\n",
        "\n",
        "# Pour limiter le nombre de calculs pendant le test, vous pouvez prendre un sous-ensemble de villes\n",
        "# Par exemple, les 10 premières villes\n",
        "# Pour le code final, utilisez toutes les villes\n",
        "# subset_cities = {k: Cities[k] for k in list(Cities.keys())[:10]}\n",
        "\n",
        "# Générer la matrice\n",
        "matrix, city_names = matrix_generation(Cities, \"driving\", link, params)\n",
        "\n",
        "# Pour une version affichable\n",
        "# printable_matrix, city_names = matrix_generation(Cities, \"driving\", link, params, True)\n",
        "# from tabulate import tabulate\n",
        "# print(\"\\n\\nListes [durée (s), distance (km)]\\n\\n\" + tabulate(printable_matrix, headers=city_names, showindex=city_names, tablefmt=\"fancy_grid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3331c43",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Generate graph ###\n",
        "def generate_complete_graph(matrix, cities):\n",
        "    import networkx as nx\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    G = nx.Graph()\n",
        "    cities_converted = {}\n",
        "    index = -1\n",
        "\n",
        "    for city1 in range(len(cities)):\n",
        "        for city2 in range(len(cities)):\n",
        "            if city1 != city2:\n",
        "                if matrix[city1][city2][1] != None:\n",
        "                    if city1 not in cities_converted: \n",
        "                        index+=1\n",
        "                        cities_converted[city1] = index\n",
        "                    if city2 not in cities_converted:\n",
        "                        index+=1\n",
        "                        cities_converted[city2] = index\n",
        "                    G.add_edge(cities_converted[city1], cities_converted[city2], weight=f\"{matrix[city1][city2][1]}\")\n",
        "            \n",
        "    pos = nx.spring_layout(G, seed=12, k=1.5)\n",
        "    nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=1000, edge_color='gray', font_size=10)\n",
        "    edge_labels = nx.get_edge_attributes(G, 'weight')\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "\n",
        "    plt.title(\"Graphe des villes avec distances\")\n",
        "    i = 0\n",
        "    plt.text(1, -1, \"\\n\".join([f\"{i} : {city}\" for i, city in enumerate(cities.keys())]), fontsize=10)\n",
        "    plt.show()\n",
        "\n",
        "def generate_hamiltonian_graph(path, path_cost, matrix, cities):\n",
        "    import networkx as nx\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    try :\n",
        "        if path[0] != path[-1]:\n",
        "            path.append(path[0])\n",
        "        G = nx.DiGraph()\n",
        "        cities_converted = {}\n",
        "        total_weight = 0\n",
        "\n",
        "        for city_index in range(len(path) - 1):\n",
        "            city1 = list(cities.items())[path[city_index]]    \n",
        "            city2 = list(cities.items())[path[city_index+1]]\n",
        "            if city1 != city2:\n",
        "                if city1 not in cities_converted: \n",
        "                    cities_converted[city1] = path[city_index]\n",
        "                if city2 not in cities_converted:\n",
        "                    cities_converted[city2] = path[city_index+1]\n",
        "\n",
        "                edge_weight = matrix[list(cities.keys()).index(city1[0])][list(cities.keys()).index(city2[0])][1]\n",
        "                total_weight += edge_weight\n",
        "                G.add_edge(cities_converted[city1], cities_converted[city2],weight=f\"{edge_weight}\")\n",
        "        \n",
        "        if path_cost != total_weight:\n",
        "            raise f\"Dissociation between given path cost and computed total weight {path_cost, total_weight}\"\n",
        "        \n",
        "        pos = nx.circular_layout(G)\n",
        "        nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, edge_color='gray', font_size=10)\n",
        "        nx.draw_networkx_edges(G, pos, edgelist=G.edges(), edge_color='gray', width=2, alpha=0.7, arrowstyle='-|>', arrowsize=20)\n",
        "        edge_labels = nx.get_edge_attributes(G, 'weight')\n",
        "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
        "        \n",
        "        plt.title(\"Graphe du chemin à suivre entre les villes\")\n",
        "        plt.text(1, -1, \"\\n\".join([f\"{i} : {city}\" for i, city in enumerate(cities.keys())]) + f\"\\n\\nCoût du chemin : {path_cost}\", fontsize=10)\n",
        "        plt.show()\n",
        "    except:\n",
        "        print(\"error during graph creation\")\n",
        "\n",
        "def generate_complete_map(cities):\n",
        "    import folium\n",
        "    import webbrowser\n",
        "    from collections import defaultdict\n",
        "    \n",
        "    french_map = folium.Map(location=[46.5, 2.5], zoom_start=6)\n",
        "    loc_cities = defaultdict(list)\n",
        "\n",
        "    for city in cities:\n",
        "        lat, lon = cities[city]\n",
        "        if (lat or lon) != None:\n",
        "            loc_cities[city].append((lat, lon))\n",
        "        else:\n",
        "            cities.pop(city)\n",
        "\n",
        "    for city in cities:\n",
        "        lat, lon = loc_cities[city][0]\n",
        "        folium.Marker(location=[lat, lon], popup=city).add_to(french_map)\n",
        "\n",
        "        for destCity in cities:\n",
        "            if destCity != city:\n",
        "                dest_lat, dest_lon = loc_cities[destCity][0]\n",
        "                folium.PolyLine([(lat, lon), (dest_lat, dest_lon)], color=\"blue\", weight=1).add_to(french_map)\n",
        "    french_map.save(\"graphe_complet_sur_carte.html\")\n",
        "    webbrowser.open(\"graphe_complet_sur_carte.html\")\n",
        "\n",
        "def generate_hamiltonian_map(path, cities):\n",
        "    import folium\n",
        "    import webbrowser\n",
        "    from collections import defaultdict\n",
        "\n",
        "    if path[0] != path[-1]:\n",
        "        path.append(path[0])\n",
        "    french_map = folium.Map(location=[46.5, 2.5], zoom_start=6)\n",
        "    loc_cities = defaultdict(list)\n",
        "\n",
        "    for city in cities:\n",
        "        lat, lon = cities[city]\n",
        "        if lat and lon:\n",
        "            loc_cities[city].append((lat, lon))\n",
        "        else:\n",
        "            cities.pop(city)\n",
        "\n",
        "    for i, city in enumerate(cities):\n",
        "        lat, lon = loc_cities[city][0]\n",
        "        folium.Marker(\n",
        "            location=[lat, lon],\n",
        "            popup=city,\n",
        "            icon=folium.DivIcon(html=f\"\"\"<div style=\"font-size: 16pt; color: white; background-color: blue; border-radius: 50%; width: 24px; height: 24px; text-align: center; line-height: 24px;\">{i}</div>\"\"\")\n",
        "        ).add_to(french_map)\n",
        "\n",
        "    for i in range(len(path) - 1):\n",
        "        city1 = list(cities.keys())[path[i]]  \n",
        "        city2 = list(cities.keys())[path[i + 1]] \n",
        "        \n",
        "        lat1, lon1 = loc_cities[city1][0]\n",
        "        lat2, lon2 = loc_cities[city2][0]\n",
        "\n",
        "        folium.PolyLine([(lat1, lon1), (lat2, lon2)], color=\"blue\", weight=2, opacity=0.6).add_to(french_map)\n",
        "\n",
        "    french_map.save(\"graphe_hamiltonien_sur_carte.html\")\n",
        "    webbrowser.open(\"graphe_hamiltonien_sur_carte.html\")\n",
        "    \n",
        "generate_complete_graph(matrix, Cities)\n",
        "generate_complete_map(Cities)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71e90dc3",
      "metadata": {},
      "source": [
        "\n",
        "##### 2.2. Justification du maintien de la modélisation\n",
        "Après vérification, aucune modification n’a donc été nécessaire dans la structure mathématique pour répondre aux objectifs du projet. Nous avons décidé de conserver la structure et les représentations formelles définies dans le livrable précédent.\n",
        "\n",
        "Cette modélisation s'est révélée suffisamment expressive pour prendre en compte l'ensemble des contraintes que nous souhaitons intégrer au problème.<br>\n",
        "De plus, notre problème est basé sur le **problème du voyageur du commerce (TSP)**, bien que nous avons démontré que ce problème est difficile (NP-complet), il est applicable à d'autres problèmes de logistique.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22f4a807",
      "metadata": {},
      "source": [
        "### 3. Méthodes de résolution\n",
        "##### 3.1. Choix des algorithmes\n",
        "Pour répondre à notre problématique, nous devons implémenter des algorithmes qui nous permettrons de trouver le chemin le plus court passant par tout les sommets de notre graphe et qui reviendra au point de départ, soit le chemin optimale ou qui se rapproche le plus de l'optimale.\n",
        "\n",
        "On avait premièrement prévu d'utiliser **l'algorithme A\\*** et un **algorithme génétique**, mais après mûre reflexion on a décidé d'utiliser **l'algorithme Held-karp** et **un algorithme génétique**.\n",
        "\n",
        "L'algorithme Held-karp est basé sur la programmation dynamique, explorant tout les sous-ensembles possibles des sommets. Il a été spécifiquement concue pour **TSP** et très efficace pour les petits graphes ($\\le$ 20 sommets).<br>\n",
        "L'algorithme A* quant à lui, est basé sur une fonction heuristique qui va d'abord explorer les chemins les plus prometteurs et effectuer une estimation du \"coût restant\" pour atteindre la solution à partir d’un état donné. Cet algorithme peut être adapté au TSP, mais nécessite une bonne heuristique.<br>\n",
        "Finalement nous allons utilisé **l'algorithme Held-karp** car il est beaucoup plus adapté à notre problème. Il nous assure une solution garantie optimale alors que l'algorithme A* ne le fera que si l'heuristique est bien pensée. Il est aussi plus simple à implémenter or que A* nécessite un gestion de files de priorité et la sauvegarde des états des sommets visités.<br>\n",
        "\n",
        "L'algorithme génétique qui imite l'évolution génétique pour trouver une bonne solution à un problème compliqué. Il va créer plusieurs solutions, les mélanger,  et en les mutant petit à petit jusqu’à ce qu’on obtienne un bon résultat. Cette algorithme ne garantie pas une solution optimale mais souvent très proche, il est cependant plus rapide que Held-karp et est efficace pour des graphes de taille plus importantes ($\\ge$ 50-100 sommets).<br>\n",
        "L'utilisation des deux algorithmes permet de combiner les avantages sur l'optimalité et la rapidité de la solution en fonction de la taille des graphes. on pourra aussi utiliser Held-karp comme référence pour évaluer la qualité des solution de l'algorithme génétique."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e550a9",
      "metadata": {},
      "source": [
        "##### 3.2. Description des algorithmes \n",
        "##### 3.2.1. Held-Karp\n",
        "L'algorithme Held-Karp ou algorithme de Bellman-Held-Kard, est un algorithme de programmation dynamique qui permet de résoudre **le problème du voyageur de commerce (TSP)**.<br>\n",
        "Cette algorithme prends en entrée une matrice de distance entre chaque ville, le but est de trouver le trajet avec une distnace minimale passant par chaque ville exactement une fois avant de revenir au point de départ, il trouve la **solution exacte** à ce problème.\n",
        "\n",
        "Dans la programmation dynamique, on divise **la tâche en sous-tâches**, pour résoudre des sous-tâches plus grandes en utilisant les résultats déjà calculés de sous-tâches plus petites, jusqu'à résoudre la tâche principale. Plutôt que de tester toutes les permutations, Held-Karp utilise la programmation dynamique pour mémoriser des sous-solutions et éviter les répétitions.<br>\n",
        "On fixe une ville départ généralement 0 et une ville d'arrivée, on calcule les distances directes de la ville de départ vers toutes les autres ${2,3,\\dots,n}$. Pour chaque ensemble de villes visitées (par exemple {0, 2, 3}), on garde en mémoire le meilleur coût pour atteindre la ville d'arrivée en ayant visité cet ensemble.\n",
        "\n",
        "Dans notre contexte, on note :\n",
        "* $V = {v_0, v_1, \\dots, v_n}$ : ensemble des sommets, le point de départ et d'arrivé est $v_0$.\n",
        "* $S$ : représente uniquement les villes intermédiaires à visiter entre le départ et le retour, $v_0$ exclus de l'ensemble c'est à dire -> $S \\subseteq {v_1, v_2, ..., v_n}$ = villes à visiter avant de revenir à $v_0$.\n",
        "* $c_{uv}$ : coût (distance) de l’arête $(u, v)$.\n",
        "* $C(S, v_k)$ : coût minimal pour aller de $v_0$ à $v_k$, en visitant exactement les sommets de $S$. Et à la fin de l’algo, on ajoute $c_{v_k v_0}$ pour revenir au dépôt, $\\min_{v_k \\in S}(C(S,v_k)+c_{v_kv_0})$\n",
        "\n",
        "##### 3.2.2. Algorithme génétique\n",
        "**L'algorithme génétique (AG)** est un algorithme évolutionniste qui permet de résoudre des problèmes complexes, qui s'inspire de la notion de sélection naturelle.<br>\n",
        "Dans un algorithme génétique, une population d'individus évolue au fil des générations pour s'approcher de la solution optimale en un temps raisonnable.\n",
        "\n",
        "l'algorithme génétique qu'on utilise est l’algorithme de colonies de fourmis (**ACO**, pour Ant Colony Optimization), un algorithme inspiré du comportement collectif des fourmis pour trouver des chemins optimaux, les fourmis déposent des phéromones sur leur passage, attirant d'autres fourmis vers les chemins les plus prometteurs.\n",
        "\n",
        "Le processus suit les étapes suivantes :\n",
        "* **Initialisation :** Création d'une population initiale aléatoire de fourmis, chacune cherchant à construire un chemin complet en visitant toutes les villes. Initialement, les niveaux de phéromones sont faibles et uniformes.\n",
        "* **Construction de solution :** Chaque fourmi construit une solution (un chemin) en se déplaçant de ville en ville exactement qu'une fois.\n",
        "* **Évaluation :** Évaluer la qualité (fitness) de chaque chemin. Ici, la fitness est souvent l'inverse de la longueur totale du chemin : plus un chemin est court, meilleur il est.\n",
        "* **Mise à jour des phéromones :** Les phéromones sont mises à jour selon les résultats :\n",
        "    * *Évaporation :* toutes les traces de phéromone diminuent un peu (pour éviter l'accumulation sur les mauvaises pistes).\n",
        "    *Renforcement :* les fourmis ayant trouvé de bons chemins renforcent les arêtes qu'elles ont empruntées en y déposant davantage de phéromone.\n",
        "* **Itération :** Le processus est répété pendant un certain nombre de cycles, la colonie convergeant progressivement vers de meilleures solutions.\n",
        "\n",
        "Dans notre contexte, chaque fourmi représente un parcours possible, c’est-à-dire une permutation des villes $v_1, v_2, ...,v_n$ (hors $v_0$, qui reste le point de départ et d’arrivée).\n",
        "Le but est de trouver un ordre des villes qui minimise la distance totale du circuit.\n",
        "Contrairement à Held-Karp qui donne une solution exacte mais coûteuse en temps et mémoire, l’algorithme de colonies de fourmis fournit une solution approchée en un temps beaucoup plus raisonnable, notamment pour des graphes de grande taille.\n",
        "##### 3.3. Complexité des algorithmes \n",
        "| Algorithme | Complexité temporelle | Complexité spatiale |\n",
        "| ----------- | ----------- | - |\n",
        "| Held-karp | $O(n^2\\cdot2^n)$ | $O(n\\cdot2^n)$ |\n",
        "| ACO | $O(w\\cdot k\\cdot n^2)$| $O(n^2+nk)$|\n",
        "\n",
        "avec :\n",
        "* $w$ = facteur empirique (non connu à l’avance) représentant le taux de convergence de l’ACO\n",
        "* $k$ = nombre de fourmis\n",
        "* $n$ = nombre de villes\n",
        "\n",
        "Held-Karp est plus rapide que la recherche exhaustive (n!), mais toujours exponentiel, donc limité à des graphes de taille moyenne (environ 20-25 sommets).\n",
        "\n",
        "L’algorithme ACO est heuristique : il ne garantit pas une solution optimale, mais permettent de trouver une bonne solution en un temps raisonnable, surtout lorsque $n$ devient grand.<br>\n",
        "La complexité dépend de paramètres comme le nombre de fourmis et la vitesse de convergence vers une solution stable, ce qui rend sa performance sensible au choix des constantes ($α,β,ρ,Q$) :\n",
        "* $α$ : influence des phéromones\n",
        "* $β$ : influence de la visibilité, soit la mesure de l'importance du fitness\n",
        "* $ρ$ : taux d’évaporation\n",
        "* $Q$ : intensité du dépôt, soit la quantité de phéromone déposée par une fourmi sur chaque arête de son parcours \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7f0a436",
      "metadata": {},
      "source": [
        "\n",
        "### 4. Implémentation\n",
        "##### 4.1. Détails de l’implémentation des algorithmes\n",
        "##### 4.1.1. Held-Karp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff85bec",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from pyprobs import Probability as pr\n",
        "import math\n",
        "\n",
        "MAX = 100000000  # Définition d'une constante MAX, qui représente un grand coût (route impraticable ou bloquée)\n",
        "\n",
        "City_Dependance = [] # Matrice des dépendances entre villes\n",
        "\n",
        "# Fonction qui va créer une matrice de dépendance entre les villes\n",
        "def generate_city_dependance(cities):\n",
        "    \"\"\"\n",
        "    Generates a city dependence matrix based on the number of cities.\n",
        "    \"\"\"\n",
        "    city_dependance = [] # Matrice vide pour stocker la dépendance ville à ville\n",
        "    for i in range(len(cities)):\n",
        "        submatrix = []\n",
        "        for j in range(len(cities)):\n",
        "            if i == j:\n",
        "                submatrix.append(0) # Pas de dépendance pour aller d'une ville à elle-même (coût 0)\n",
        "            else:\n",
        "                road_blocked = pr.prob(0.25)  # Avec 25% de chance la route entre deux villes sera bloquée (0)\n",
        "                if road_blocked:\n",
        "                    submatrix.append(0)\n",
        "                else:\n",
        "                    submatrix.append(1)\n",
        "        city_dependance.append(submatrix)\n",
        "    return city_dependance\n",
        "City_Dependance = generate_city_dependance(Cities) # Génération de la matrice de dépendances pour toutes les villes existantes\n",
        "\n",
        "# Fonction pour générer la matrice de pondération basée sur les distances/temps + risques de blocages\n",
        "def generate_ponderation_matrix(matrix):\n",
        "    ponderation_matrix = [] # Matrice vide pour stocker les coûts pondérés\n",
        "\n",
        "    for i in range(len(matrix)):\n",
        "        submatrix = []\n",
        "        for j in range(len(matrix[i])):\n",
        "            road_blocked = pr.prob(0.05)# Avec 5% de probabilité, même si dans City_Dependance une route est autorisée (1), il peut y avoir en plus un \"accident\" aléatoire qui bloque la route\n",
        "            road_cost = random.uniform(0.6, 1.4) #  Choisis aléatoirement un nombre réel entre 0.6 et 1.4\n",
        "\n",
        "            if road_blocked or matrix[i][j][0] == 0:\n",
        "                submatrix.append(MAX)\n",
        "            else:\n",
        "                distance = matrix[i][j][0]\n",
        "                time = matrix[i][j][1]\n",
        "                cost = int(distance * 0.7) + int(time * 0.5 * road_cost) # road_cost rend certains trajets plus longs ou plus rapides de façon aléatoire\n",
        "                submatrix.append(cost)\n",
        "\n",
        "        ponderation_matrix.append(submatrix)\n",
        "\n",
        "    return ponderation_matrix\n",
        "ponderation_matrix = generate_ponderation_matrix(matrix) # Matrice de pondération basée sur la matrice de distances/temps (matrix).\n",
        "\n",
        "def calcul_fitness(chemin, matrice_ponderation, City_Dependance):\n",
        "    \"\"\"\n",
        "    Calcule la distance totale d'un chemin donné dans la matrice de distances.\n",
        "    \"\"\"\n",
        "    ponderation_totale = 0\n",
        "    for i in range(len(chemin) - 1):\n",
        "        if matrice_ponderation[chemin[i]][chemin[i + 1]] == MAX:\n",
        "            return MAX\n",
        "        elif City_Dependance[chemin[i]][chemin[i + 1]] == 0:\n",
        "            return MAX\n",
        "        elif City_Dependance[chemin[i]][chemin[i + 1]] == 1:\n",
        "            ponderation_totale += matrice_ponderation[chemin[i]][chemin[i + 1]]\n",
        "    return ponderation_totale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c7204d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "def held_karp(dist, start=0):\n",
        "    import itertools\n",
        "    n = len(dist) # Nombre total de villes\n",
        "    C = {} # Dictionnaire vide pour mémoriser les meilleurs coûts et chemins trouvés\n",
        "\n",
        "    # Initialisation pour les paires de 2 villes (start, k)\n",
        "    for k in range(n):\n",
        "        if k == start:\n",
        "            continue # Ignore la ville de départ\n",
        "        C[(frozenset([k]), k)] = (dist[start][k], [start, k]) # Initialise le coût pour aller directement du départ à chaque ville k, stocke le coût et le chemin start -> k\n",
        "\n",
        "    # Construction progressive des plus grands sous-ensembles\n",
        "    for subset_size in tqdm(range(2, n)): # Pour chaque taille de sous-ensemble de villes (2, puis 3, 4, ..., jusqu'à n-1)\n",
        "        for subset in tqdm(itertools.combinations([i for i in range(n) if i != start], subset_size)):\n",
        "            S = frozenset(subset) # S est l'ensemble représentant les villes visitées dans ce sous-ensemble\n",
        "            for k in subset:\n",
        "                prev_subset = S - {k} # Sous-ensemble sans la ville k pour voir comment on est arrivé jusque-là\n",
        "                # On initialise le meilleur coût et le meilleur chemin avec des valeurs très mauvaises pour les améliorer ensuite\n",
        "                min_cost = 1000000000\n",
        "                min_path = []\n",
        "\n",
        "                for m in prev_subset: # Pour chaque ville m possible avant k\n",
        "                    prev_cost, prev_path = C.get((prev_subset, m), (1000000000, []))\n",
        "                    cost = prev_cost + dist[m][k]\n",
        "                    \n",
        "                    #Si ce nouveau chemin est meilleur on le garde en mémoire\n",
        "                    if cost < min_cost:\n",
        "                        min_cost = cost\n",
        "                        min_path = prev_path + [k]\n",
        "\n",
        "                C[(S, k)] = (min_cost, min_path)\n",
        "\n",
        "    # Réinitialise les meilleures valeurs pour trouver le chemin optimal final\n",
        "    full_set = frozenset([i for i in range(n) if i != start]) # Crée l'ensemble complet des villes à visiter (sans départ)\n",
        "    min_cost = 1000000000\n",
        "    min_path = []\n",
        "\n",
        "    for k in range(n):\n",
        "        if k == start:\n",
        "            continue\n",
        "        # Récupère le meilleur coût pour aller jusqu'à k en visitant toutes les villes\n",
        "        cost, path = C.get((full_set, k), (1000000000, []))\n",
        "        total_cost = cost + dist[k][start]\n",
        "        if total_cost < min_cost:\n",
        "            min_cost = total_cost\n",
        "            min_path = path + [start]\n",
        "\n",
        "    return min_cost, min_path\n",
        "\n",
        "def adjusted_cost(i, j, dist, City_Dependance):\n",
        "    base_cost = dist[i][j]\n",
        "    penalty =  MAX if not City_Dependance[i][j] else 0\n",
        "    return base_cost + penalty\n",
        "\n",
        "def build_adjusted_matrix(dist, City_Dependance):\n",
        "    n = len(dist)\n",
        "    fitness_dist = np.zeros_like(dist)\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                fitness_dist[i][j] = 0\n",
        "            else:\n",
        "                fitness_dist[i][j] = adjusted_cost(i, j, dist, City_Dependance)\n",
        "    return fitness_dist\n",
        "\n",
        "adjusted_dist = build_adjusted_matrix(ponderation_matrix, City_Dependance)\n",
        "\n",
        "start_time = datetime.datetime.now() # Démarre un chronomètre avant de lancer l'algorithme\n",
        "min_cost, path = held_karp(ponderation_matrix, start=0) # Lance held_karp sur la matrice de distances ponderation_matrix\n",
        "end_time = datetime.datetime.now() # Stoppe le chronomètre après l'exécution\n",
        "print(f\"Coût minimum : {min_cost}\\nChemin : {path}\\nTemps de calcul : {end_time-start_time}\")\n",
        "generate_hamiltonian_graph(path, min_cost, ponderation_matrix, Cities)\n",
        "generate_hamiltonian_map(path, Cities)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "955d81db",
      "metadata": {},
      "source": [
        "##### 4.1.2. Algorithme génétique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31ca7069",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datetime, random\n",
        "\n",
        "def initialiser_pheromones(n, valeur_initiale=0.1):\n",
        "    return np.ones((n, n)) * valeur_initiale\n",
        "\n",
        "def selectionner_prochaine_ville(ville_actuelle, villes_non_visitees, pheromones, matrice_poids, importance_pheromone, importance_cout\n",
        "):\n",
        "    if not villes_non_visitees:\n",
        "        return None\n",
        "    \n",
        "    proba_totale = 0\n",
        "    probabilites = {}\n",
        "    \n",
        "    for ville in villes_non_visitees:\n",
        "        tau = pheromones[ville_actuelle][ville]\n",
        "        attractivite = 1.0 / max(0.1, matrice_poids[ville_actuelle][ville]) # si distance faible , plus attractif\n",
        "        probabilite = (tau ** importance_pheromone) * (attractivite ** importance_cout) # Formule de probabilité selon algo colonie de fourmis\n",
        "        probabilites[ville] = probabilite\n",
        "        proba_totale += probabilite\n",
        "    \n",
        "    if proba_totale == 0:\n",
        "        return random.choice(villes_non_visitees)\n",
        "    \n",
        "    r = random.random() * proba_totale # choix selon roulette biaisé \n",
        "    cumul = 0\n",
        "    \n",
        "    for ville, proba in probabilites.items():\n",
        "        cumul += proba\n",
        "        if cumul >= r:\n",
        "            return ville\n",
        "    \n",
        "    return villes_non_visitees[0]\n",
        "\n",
        "def construire_solution(matrice_ponderation, pheromones, importance_pheromone, importance_cout, depart):\n",
        "\n",
        "    n = len(matrice_ponderation)\n",
        "\n",
        "    ville_depart = depart if depart is not None else random.randint(0, n - 1)\n",
        "    \n",
        "    chemin = [ville_depart]\n",
        "    villes_non_visitees = list(range(len(matrice_ponderation)))\n",
        "    villes_non_visitees.remove(ville_depart)\n",
        "    \n",
        "    ville_actuelle = ville_depart\n",
        "    \n",
        "    while villes_non_visitees:\n",
        "        prochaine_ville = selectionner_prochaine_ville(\n",
        "            ville_actuelle, \n",
        "            villes_non_visitees, \n",
        "            pheromones, \n",
        "            matrice_ponderation, \n",
        "            importance_pheromone, \n",
        "            importance_cout\n",
        "        )\n",
        "        \n",
        "        chemin.append(prochaine_ville)\n",
        "        villes_non_visitees.remove(prochaine_ville)\n",
        "        ville_actuelle = prochaine_ville\n",
        "    chemin.append(chemin[0])\n",
        "    return chemin\n",
        "\n",
        "def mettre_a_jour_pheromones(pheromones, chemins, fitness_values, taux_evap):\n",
        "    pheromones = pheromones * (1 - taux_evap)\n",
        "    \n",
        "    for i, chemin in enumerate(chemins):\n",
        "        fitness = fitness_values[i]\n",
        "        if fitness == 0 or fitness == float('inf'):\n",
        "            continue\n",
        "            \n",
        "        depot = 1.0 / fitness\n",
        "        \n",
        "        for j in range(len(chemin) - 1):\n",
        "            ville_a, ville_b = chemin[j], chemin[j + 1]\n",
        "            pheromones[ville_a][ville_b] += depot\n",
        "            pheromones[ville_b][ville_a] += depot\n",
        "        \n",
        "        ville_a, ville_b = chemin[-1], chemin[0]\n",
        "        pheromones[ville_a][ville_b] += depot\n",
        "        pheromones[ville_b][ville_a] += depot\n",
        "    \n",
        "    return pheromones\n",
        "\n",
        "def executer_aco(matrice_poids, City_Dependance, nb_fourmis=10, nb_iterations=100, \n",
        "                importance_pheromone=1.0, importance_cout=2.0, taux_evap=0.1, depart=None):\n",
        "    n = len(matrice_poids)\n",
        "    \n",
        "    pheromones = initialiser_pheromones(n)\n",
        "    \n",
        "    meilleur_chemin = None\n",
        "    meilleure_fitness = float('inf')\n",
        "    \n",
        "    for iteration in range(nb_iterations):\n",
        "        chemins = []\n",
        "        fitness_values = []\n",
        "        \n",
        "        for i in range(nb_fourmis):\n",
        "            chemin = construire_solution(matrice_poids, pheromones, importance_pheromone, importance_cout, depart)\n",
        "            \n",
        "            fitness = calcul_fitness(chemin, matrice_poids, City_Dependance)\n",
        "            \n",
        "            chemins.append(chemin)\n",
        "            fitness_values.append(fitness)\n",
        "                        \n",
        "            if fitness < meilleure_fitness:\n",
        "                meilleure_fitness = fitness\n",
        "                meilleur_chemin = chemin.copy()\n",
        "        \n",
        "        pheromones = mettre_a_jour_pheromones(pheromones, chemins, fitness_values, taux_evap)\n",
        "        \n",
        "        # if (iteration + 1) % 10 == 0:\n",
        "        #     print(f\"Itération {iteration + 1}/{nb_iterations}, Meilleure fitness: {meilleure_fitness}\")\n",
        "    \n",
        "    return meilleur_chemin, meilleure_fitness\n",
        "\n",
        "start_time = datetime.datetime.now()\n",
        "meilleur_chemin, meilleure_fitness = executer_aco(ponderation_matrix, City_Dependance, nb_fourmis=10, nb_iterations=100, importance_pheromone=1.0, importance_cout=2.0, taux_evap=0.1, depart=0)\n",
        "end_time = datetime.datetime.now()\n",
        "print(f\"Meilleur chemin trouvé : {meilleur_chemin}\")\n",
        "print(f\"Meilleure fitness : {meilleure_fitness}\")\n",
        "print(f\"En {end_time - start_time}\")\n",
        "generate_hamiltonian_graph(meilleur_chemin, meilleure_fitness, ponderation_matrix, Cities)\n",
        "generate_hamiltonian_map(meilleur_chemin, Cities)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a20cb05",
      "metadata": {},
      "source": [
        "\n",
        "##### 4.2. Cas de test représentatifs\n",
        "##### 4.3. Résultats observés sur les tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f4790e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "from itertools import product\n",
        "\n",
        "def run_experiments(matrice_poids, City_Dependance, param_ranges):\n",
        "    results = []\n",
        "    param_combinations = list(product(*param_ranges.values()))\n",
        "    \n",
        "    for params in tqdm(param_combinations):\n",
        "        nb_fourmis, nb_iterations, importance_pheromone, importance_cout, taux_evap = params\n",
        "        start_time = datetime.datetime.now()\n",
        "        _, fitness = executer_aco(\n",
        "            matrice_poids, \n",
        "            City_Dependance,\n",
        "            nb_fourmis=nb_fourmis,\n",
        "            nb_iterations=nb_iterations,\n",
        "            importance_pheromone=importance_pheromone,\n",
        "            importance_cout=importance_cout,\n",
        "            taux_evap=taux_evap\n",
        "        )\n",
        "        end_time = datetime.datetime.now()\n",
        "        duration = (end_time - start_time).total_seconds()\n",
        "        \n",
        "        results.append({\n",
        "            'params': params,\n",
        "            'fitness': fitness,\n",
        "            'time': duration\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "def plot_results(results, param_ranges):\n",
        "    param_names = ['nb_fourmis', 'nb_iterations', 'importance_pheromone', 'importance_cout', 'taux_evap']\n",
        "    \n",
        "    for i, param in enumerate(param_names):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        x_values = [r['params'][i] for r in results]\n",
        "        y_values = [r['fitness'] for r in results]\n",
        "        \n",
        "        unique_params = sorted(list(set(x_values)))\n",
        "        avg_fitness = []\n",
        "        \n",
        "        for p in unique_params:\n",
        "            mask = [x == p for x in x_values]\n",
        "            avg_fitness.append(np.mean([y for y, m in zip(y_values, mask) if m]))\n",
        "        \n",
        "        plt.plot(unique_params, avg_fitness, 'o-')\n",
        "        plt.xlabel(param)\n",
        "        plt.ylabel('Average Fitness')\n",
        "        plt.title(f'Impact of {param} on Solution Quality')\n",
        "        plt.grid(True)\n",
        "        i=0\n",
        "        while not os.path.join(f\"./benchmarks/fourmies/{param}_{i}.png\"):\n",
        "            i += 1\n",
        "        plt.savefig(f\"./benchmarks/fourmies/{param}_{i}.png\")\n",
        "        plt.show()\n",
        "\n",
        "def analyze_parameters(matrice_poids, City_Dependance):\n",
        "    param_ranges = {\n",
        "        'nb_fourmis': [5, 10, 20, 50],\n",
        "        'nb_iterations': [50, 100, 200],\n",
        "        'importance_pheromone': [0.5, 1.0, 2.0],\n",
        "        'importance_cout': [0.5, 1.0, 2.0],\n",
        "        'taux_evap': [0.05, 0.1, 0.2]\n",
        "    }\n",
        "    \n",
        "    results = run_experiments(matrice_poids, City_Dependance, param_ranges)\n",
        "    plot_results(results, param_ranges)\n",
        "    \n",
        "    best_result = min(results, key=lambda x: x['fitness'])\n",
        "    print(\"\\nBest Parameters:\")\n",
        "    print(f\"nb_fourmis: {best_result['params'][0]}\")\n",
        "    print(f\"nb_iterations: {best_result['params'][1]}\")\n",
        "    print(f\"importance_pheromone: {best_result['params'][2]}\")\n",
        "    print(f\"importance_cout: {best_result['params'][3]}\")\n",
        "    print(f\"taux_evap: {best_result['params'][4]}\")\n",
        "    print(f\"Best Fitness: {best_result['fitness']}\")\n",
        "    print(f\"Execution Time: {best_result['time']} seconds\")\n",
        "\n",
        "analyze_parameters(ponderation_matrix, City_Dependance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb7e5b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_32 = pd.read_csv(\"benchmarks\\weighted_matrix.csv\", on_bad_lines='skip')\n",
        "\n",
        "matrice = []\n",
        "with open(\"./benchmarks/matrice200.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:  \n",
        "            line = line.replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "            items = line.split(\",\")\n",
        "            row = []\n",
        "            for item in items:\n",
        "                try:\n",
        "                    row.append(float(item.strip())) \n",
        "                except ValueError:\n",
        "                    print(f\"Erreur de conversion pour l'élément : {item}\")\n",
        "            matrice.append(row)\n",
        "\n",
        "\n",
        "df_200 = pd.DataFrame(matrice)\n",
        "print(df_200)\n",
        "first_city = 0\n",
        "\n",
        "hk_result_list = []\n",
        "ants_result_list = []\n",
        "hk_duration = []\n",
        "ants_duration = []\n",
        "\n",
        "City_Dependance = generate_city_dependance(df_200.columns[:185])\n",
        "df_reduit = df_200.iloc[:185, :185]\n",
        "ponderation_matrix = df_reduit.to_numpy()\n",
        "\n",
        "adjusted_dist = build_adjusted_matrix(ponderation_matrix, City_Dependance)\n",
        "\n",
        "analyze_parameters(adjusted_dist, City_Dependance)\n",
        "\n",
        "for i in range(3, len(df_32.columns)-1):\n",
        "    print(f\"Start with i as {i}\")\n",
        "    City_Dependance = generate_city_dependance(df_32.columns[:i])\n",
        "    df_reduit = df_32.iloc[:i, :i]\n",
        "    ponderation_matrix = df_reduit.to_numpy()\n",
        "\n",
        "    adjusted_dist = build_adjusted_matrix(ponderation_matrix, City_Dependance)\n",
        "    if i < 23:\n",
        "        start_time = datetime.datetime.now()\n",
        "        min_cost, path = held_karp(adjusted_dist, start=first_city)\n",
        "        end_time = datetime.datetime.now()\n",
        "        hk_result_list.append(min_cost if min_cost < MAX else 0)\n",
        "        hk_duration.append((end_time - start_time).total_seconds())\n",
        "\n",
        "    start_time = datetime.datetime.now()\n",
        "    ants_path, ants_result =  executer_aco(ponderation_matrix, City_Dependance, nb_fourmis=10, nb_iterations=100, importance_pheromone=1.0, importance_cout=2.0, taux_evap=0.1, depart=first_city)\n",
        "    end_time = datetime.datetime.now()\n",
        "    ants_result_list.append(ants_result if ants_result < MAX else 0)\n",
        "    ants_duration.append((end_time - start_time).total_seconds())\n",
        "\n",
        "    # print(f\"{np.array(City_Dependance)}\\nheld result :{path} - cost {min_cost} \\nants result :{ants_path} - cost {ants_result}\")\n",
        "\n",
        "\n",
        "x = np.arange(3, 3 + len(hk_result_list))  \n",
        "width = 0.35  \n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "print(f\"{hk_result_list}\\n{ants_result_list}\")\n",
        "ax.bar(x - width/2, hk_result_list, width=width, color='skyblue', label='Held-Karp')\n",
        "ax.bar(x + width/2, ants_result_list, width=width, color='red', label='Ants')\n",
        "\n",
        "for i, val in enumerate(hk_result_list):\n",
        "    ax.text(x[i] - width/2, val / 2, f\"{val:.1f}\", ha='center', va='center', fontsize=12, rotation=90, color='black')\n",
        "\n",
        "for i, val in enumerate(ants_result_list):\n",
        "    ax.text(x[i] + width/2, val / 2, f\"{val:.1f}\", ha='center', va='center', fontsize=12, rotation=90, color='white')\n",
        "\n",
        "for i in range(len(x)):\n",
        "    hk_val = hk_result_list[i]\n",
        "    ants_val = ants_result_list[i]\n",
        "    max_height = max(hk_val, ants_val)\n",
        "    mid_x = x[i]  # au milieu du couple de barres\n",
        "\n",
        "    # Exemple : différence absolue\n",
        "    ax.text(mid_x, max_height + 1, f\"Diff: {100*(ants_val/hk_val):0.1f} %\" if hk_val > 0 else \"\", ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "ax.set_xlabel('Nombre de villes')\n",
        "ax.set_ylabel('Coût minimum')\n",
        "ax.set_title('Comparaison Held-Karp vs Ants')\n",
        "ax.set_xticks(x)  # Positionne les labels\n",
        "\n",
        "mean_ants = (sum(ants_result_list) / len(ants_result_list))\n",
        "mean_hk = (sum(hk_result_list) / len(hk_result_list))\n",
        "\n",
        "label_pourcent_diff = mpatches.Patch(color='none', label=f\"Moyenne des différences de held-karp à l'algorithme des fourmies : {((mean_ants/mean_hk)*100):.1f}%\")\n",
        "\n",
        "ax.legend(handles=[*ax.get_legend_handles_labels()[0], label_pourcent_diff])\n",
        "ax.grid(axis='y')\n",
        "\n",
        "ax.set_xticklabels([f\"{i} villes\" for i in x], rotation=90, ha='center')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"./benchmarks/bar_processing.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"Comparaison des temps de travail\")\n",
        "plt.xlabel(\"Taille de la matrice (indice)\")\n",
        "plt.ylabel(\"durée (en secondes)\")\n",
        "\n",
        "plt.plot(list(range(len(hk_duration))), hk_duration, label=\"Held-Karp\", marker='o')\n",
        "plt.plot(list(range(len(ants_duration))), ants_duration, label=\"Ants\", marker='s')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"./benchmarks/plot_processing_time.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49b2a7d1",
      "metadata": {},
      "source": [
        "### 5. Étude expérimentale\n",
        "##### 5.1. Méthodologie du plan d’expérience\n",
        "##### 5.2. Analyse des performances\n",
        "Nous constatons des performances très similaires entre les algorithmes Held-Karp et ACO jusqu’à 10 villes. Au-delà de ce seuil, le temps de calcul de Held-Karp devient prohibitif, tandis que celui de l’algorithme ACO reste stable. Cela démontre la capacité de l’ACO à approcher efficacement une solution optimale, avec un écart d’environ 8 % par rapport à celle de Held-Karp sur un problème à 20 villes et uniquement 100 génération et 10 individus pour ACO\n",
        "##### 5.3. Limites observées\n",
        "Concernant l’algorithme ACO, le nombre de solutions possibles pour un problème de type TSP est de l’ordre de n! (factorielle de n). Ainsi, lorsque le nombre de villes devient trop important, l’espace de recherche devient trop vaste. Même avec un temps de calcul prolongé, l’algorithme peut ne pas converger vers une solution satisfaisante en raison de la complexité croissante du problème.\n",
        "\n",
        "##### 5.4. Perspectives d’amélioration\n",
        "Une piste d’amélioration pour les deux algorithmes serait de diviser le problème en plusieurs sous-problèmes ou sous-chemins, qui seraient ensuite reliés pour former une solution globale au problème TSP. Cette approche permettrait d’améliorer les performances sur des cas de grande taille. D’autres pistes, comme l’optimisation des paramètres de l’ACO ou l’hybridation avec d’autres heuristiques, peuvent également être envisagées."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c739ce2f",
      "metadata": {},
      "source": [
        "\n",
        "### 6. Plan de Travail et Organisation du Projet\n",
        "##### 6.1. Étapes prévues \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8545b23c",
      "metadata": {},
      "source": [
        "### 7. Conclusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1053d7db",
      "metadata": {},
      "source": [
        "### 8. Annexes\n",
        "##### 8.1. Glossaire\n",
        "* **Programmation dynamique :** Technique de programmation visant à donner les solutions optimales à un problème P. La méthode s’applique lorsque la résolution de P peut se faire en résolvant r sous-problèmes P1, ..., Pr. \n",
        "* **Algorithme heuristique :** Méthode de résolution de problèmes qui utilise des règles pratiques ou des approximations pour trouver des solutions satisfaisantes dans un délai raisonnable, même si ces solutions ne sont pas nécessairement optimales. (exemple : algo glouton) \n",
        "* **Algorithme évolutionniste :** [Le principe s'inspire de la théorie de l'évolution pour résoudre des problèmes divers, l'idée est de faire évoluer un ensemble de solutions à un problème donné, dans l'optique de trouver les meilleurs résultats.](https://fr.wikipedia.org/wiki/Algorithme_%C3%A9volutionniste#:~:text=Les%20algorithmes%20%C3%A9volutionnistes,processus%20al%C3%A9atoires.)\n",
        "* **Branch & Bound (séparation et évaluation) :** Méthode d'optimisation utilisée pour résoudre des problèmes d'optimisation combinatoire, particulièrement ceux qui nécessitent de trouver une solution optimale parmi un grand nombre de possibilités.<br>\n",
        "Le principe fondamental de cet algorithme repose sur deux concepts clés :\n",
        "    * *Branch (Séparation) :* Il s'agit de diviser l'espace des solutions en sous-problèmes plus petits (branches). Pour un problème d'optimisation combinatoire, cela revient souvent à construire un arbre de décision où chaque nœud représente un choix partiel.\n",
        "    * *Bound (Évaluation) :* On calcule des bornes (inférieures pour un problème de minimisation, supérieures pour un problème de maximisation) pour chaque sous-problème. Ces bornes permettent d'estimer la qualité de la meilleure solution possible dans cette branche.\n",
        "\n",
        "##### 8.2. Références bibliographiques\n",
        "* [Algorithmes génétiques : Jean-Phillipe Préaux](https://www.i2m.univ-amu.fr/perso/jean-philippe.preaux/PDF/pdf_proteges/OptimisationCombinatoire/Metaheuristiques3.pdf)\n",
        "* [Algorithmes génétiques : Wikipedia](https://fr.wikipedia.org/wiki/Algorithme_g%C3%A9n%C3%A9tique)\n",
        "* [Algorithmes génétiques : Ionos](https://www.ionos.fr/digitalguide/sites-internet/developpement-web/genetic-algorithm/)\n",
        "##### 8.3. Annexes techniques "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
